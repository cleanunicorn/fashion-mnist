{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as pt\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device('cpu')\n",
    "\n",
    "# if torch.cuda.is_available() > 0:\n",
    "#     print(\"Using GPU\")\n",
    "#     device = torch.device('cuda')\n",
    "# else:\n",
    "#     print(\"Using CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sizes of layers and batch size\n",
    "n_in, n_h, n_out = 784, 200, 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data length: 42000\n"
     ]
    }
   ],
   "source": [
    "# Load test data\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"./train.csv\").values\n",
    "\n",
    "# \n",
    "print(\"Data length: {}\".format(len(data)))\n",
    "\n",
    "# training dataset\n",
    "train_size = len(data)\n",
    "train_data = data[0:train_size, 1:]\n",
    "train_label = data[0:train_size,0]\n",
    "\n",
    "# testing data\n",
    "# xtest = data[21000:, 1:]\n",
    "# actual_label = data[21000:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_index = 0\n",
    "\n",
    "d = train_data[test_index]\n",
    "d.shape=(28,28)\n",
    "pt.imshow(255-d,cmap='gray')\n",
    "pt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "[5000] loss: 0.08443897385801673\n",
      "[10000] loss: 0.07238239994006218\n",
      "[15000] loss: 0.06838011152572177\n",
      "[20000] loss: 0.067749574535047\n",
      "[25000] loss: 0.0672565799288743\n",
      "[30000] loss: 0.06491287572208082\n",
      "[35000] loss: 0.06281795144077003\n",
      "[40000] loss: 0.06068375709742644\n",
      "epoch: 1\n",
      "[5000] loss: 0.05897358498494777\n",
      "[10000] loss: 0.05980399995432821\n",
      "[15000] loss: 0.0581566582131322\n",
      "[20000] loss: 0.057798753923296774\n",
      "[25000] loss: 0.05502325309740843\n",
      "[30000] loss: 0.053453063121645265\n",
      "[35000] loss: 0.05272032273397122\n",
      "[40000] loss: 0.051085313344987913\n",
      "epoch: 2\n",
      "[5000] loss: 0.05013699505721219\n",
      "[10000] loss: 0.04930938820244464\n",
      "[15000] loss: 0.04309774818060343\n",
      "[20000] loss: 0.04259904995055509\n",
      "[25000] loss: 0.041737495217212484\n",
      "[30000] loss: 0.04097819300129548\n",
      "[35000] loss: 0.04115129624640428\n",
      "[40000] loss: 0.03973798949835453\n",
      "epoch: 3\n",
      "[5000] loss: 0.03738859885083407\n",
      "[10000] loss: 0.0369726333700325\n",
      "[15000] loss: 0.032564151343975216\n",
      "[20000] loss: 0.03195294875765799\n",
      "[25000] loss: 0.031669474888930065\n",
      "[30000] loss: 0.031947806716890105\n",
      "[35000] loss: 0.03071975116377539\n",
      "[40000] loss: 0.029317932221446796\n",
      "epoch: 4\n",
      "[5000] loss: 0.02853593331134086\n",
      "[10000] loss: 0.029745651371399767\n",
      "[15000] loss: 0.028791005774741717\n",
      "[20000] loss: 0.028434348349224366\n",
      "[25000] loss: 0.028569501638752062\n",
      "[30000] loss: 0.029147298223243717\n",
      "[35000] loss: 0.02898170470020628\n",
      "[40000] loss: 0.02725534713073197\n",
      "epoch: 5\n",
      "[5000] loss: 0.026720095865542817\n",
      "[10000] loss: 0.028527077085638966\n",
      "[15000] loss: 0.02746070764976989\n",
      "[20000] loss: 0.027312691270550006\n",
      "[25000] loss: 0.027680938597134542\n",
      "[30000] loss: 0.028002036146068825\n",
      "[35000] loss: 0.027178773209813767\n",
      "[40000] loss: 0.02637835331290808\n",
      "epoch: 6\n",
      "[5000] loss: 0.02607914837565362\n",
      "[10000] loss: 0.02758683380359609\n",
      "[15000] loss: 0.026318294995804233\n",
      "[20000] loss: 0.02621539282971283\n",
      "[25000] loss: 0.026419852565452366\n",
      "[30000] loss: 0.02666582367841326\n",
      "[35000] loss: 0.02650567341114691\n",
      "[40000] loss: 0.0256529965331183\n",
      "epoch: 7\n",
      "[5000] loss: 0.02468214136128707\n",
      "[10000] loss: 0.026841872278110065\n",
      "[15000] loss: 0.025531757391184358\n",
      "[20000] loss: 0.025385635489852898\n",
      "[25000] loss: 0.026007299687040308\n",
      "[30000] loss: 0.025989260860805077\n",
      "[35000] loss: 0.024355316977236034\n",
      "[40000] loss: 0.02227113586467968\n",
      "epoch: 8\n",
      "[5000] loss: 0.01930006293384331\n",
      "[10000] loss: 0.019665399687899793\n",
      "[15000] loss: 0.018776855642958768\n",
      "[20000] loss: 0.018023230822345603\n",
      "[25000] loss: 0.018597005581080735\n",
      "[30000] loss: 0.018368679081203872\n",
      "[35000] loss: 0.017136838693624395\n",
      "[40000] loss: 0.0169667627383269\n",
      "epoch: 9\n",
      "[5000] loss: 0.016211653102497482\n",
      "[10000] loss: 0.017064793050445327\n",
      "[15000] loss: 0.015938533854938982\n",
      "[20000] loss: 0.015994793646681337\n",
      "[25000] loss: 0.01673234928555841\n",
      "[30000] loss: 0.016827814250711982\n",
      "[35000] loss: 0.015607769665014067\n",
      "[40000] loss: 0.016185020957305053\n",
      "epoch: 10\n",
      "[5000] loss: 0.015632176258982305\n",
      "[10000] loss: 0.015790073048663963\n",
      "[15000] loss: 0.01499891981756208\n",
      "[20000] loss: 0.015797544248874168\n",
      "[25000] loss: 0.015968325985071745\n",
      "[30000] loss: 0.0159817396752001\n",
      "[35000] loss: 0.014806073725951458\n",
      "[40000] loss: 0.015625302239309906\n",
      "epoch: 11\n",
      "[5000] loss: 0.014742130604176102\n",
      "[10000] loss: 0.015331769296696888\n",
      "[15000] loss: 0.014201647203740612\n",
      "[20000] loss: 0.014804826830353108\n",
      "[25000] loss: 0.01542052007310684\n",
      "[30000] loss: 0.015161541038949983\n",
      "[35000] loss: 0.014138689041406803\n",
      "[40000] loss: 0.014675139053540908\n",
      "epoch: 12\n",
      "[5000] loss: 0.014096448356080652\n",
      "[10000] loss: 0.014875128583896932\n",
      "[15000] loss: 0.013990992394206266\n",
      "[20000] loss: 0.014181010243879234\n",
      "[25000] loss: 0.01484678778224156\n",
      "[30000] loss: 0.014815002536038645\n",
      "[35000] loss: 0.013699541108592147\n",
      "[40000] loss: 0.01427043101266316\n",
      "epoch: 13\n",
      "[5000] loss: 0.013735958369211121\n",
      "[10000] loss: 0.014689037852766268\n",
      "[15000] loss: 0.013581867476901025\n",
      "[20000] loss: 0.0138814801270412\n",
      "[25000] loss: 0.014729368230561122\n",
      "[30000] loss: 0.014465604978622235\n",
      "[35000] loss: 0.01311625241235603\n",
      "[40000] loss: 0.013961091415298417\n",
      "epoch: 14\n",
      "[5000] loss: 0.013324277256071031\n",
      "[10000] loss: 0.014354500261049478\n",
      "[15000] loss: 0.012980601413016612\n",
      "[20000] loss: 0.013591514729520535\n",
      "[25000] loss: 0.01452850007833403\n",
      "[30000] loss: 0.013989753890752766\n",
      "[35000] loss: 0.013358051446663032\n",
      "[40000] loss: 0.013737727598699333\n",
      "epoch: 15\n",
      "[5000] loss: 0.01316565445250619\n",
      "[10000] loss: 0.01398342128803773\n",
      "[15000] loss: 0.012972676302791456\n",
      "[20000] loss: 0.01319050074143006\n",
      "[25000] loss: 0.014362866156387776\n",
      "[30000] loss: 0.013772692161302037\n",
      "[35000] loss: 0.01299080073854104\n",
      "[40000] loss: 0.013564849387826405\n",
      "epoch: 16\n",
      "[5000] loss: 0.0128417661939612\n",
      "[10000] loss: 0.013818624057155256\n",
      "[15000] loss: 0.012440320828377021\n",
      "[20000] loss: 0.01290336707185941\n",
      "[25000] loss: 0.013984864017572648\n",
      "[30000] loss: 0.013727437372783882\n",
      "[35000] loss: 0.012610223623551487\n",
      "[40000] loss: 0.013080908738317654\n",
      "epoch: 17\n",
      "[5000] loss: 0.012719430051132626\n",
      "[10000] loss: 0.01329885014669125\n",
      "[15000] loss: 0.012392134940794833\n",
      "[20000] loss: 0.012687913996162406\n",
      "[25000] loss: 0.013695282912575006\n",
      "[30000] loss: 0.013456370562941853\n",
      "[35000] loss: 0.012277919187460174\n",
      "[40000] loss: 0.013289082027235319\n",
      "epoch: 18\n",
      "[5000] loss: 0.012610141652022172\n",
      "[10000] loss: 0.012862753683690668\n",
      "[15000] loss: 0.012019208026023489\n",
      "[20000] loss: 0.012637807537728902\n",
      "[25000] loss: 0.013297080544592714\n",
      "[30000] loss: 0.013113335915284862\n",
      "[35000] loss: 0.012060042716293283\n",
      "[40000] loss: 0.012836156950747449\n",
      "epoch: 19\n",
      "[5000] loss: 0.012207529474396867\n",
      "[10000] loss: 0.012939677316620567\n",
      "[15000] loss: 0.011807223306512541\n",
      "[20000] loss: 0.012455984507757792\n",
      "[25000] loss: 0.01339175103161663\n",
      "[30000] loss: 0.013077330847338593\n",
      "[35000] loss: 0.012015029950431822\n",
      "[40000] loss: 0.012793864322790349\n",
      "CPU times: user 1h 19min 17s, sys: 14.9 s, total: 1h 19min 32s\n",
      "Wall time: 11min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# print(len(trainloader))\n",
    "\n",
    "# Create model\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(n_in, n_h),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(n_h, n_out),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "\n",
    "# if torch.cuda.is_available() > 0:\n",
    "model.to(device)\n",
    "\n",
    "# Criterion\n",
    "criterion = torch.nn.MSELoss()\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer function\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "# Cast as double\n",
    "model.double()\n",
    "\n",
    "# Generate correct results\n",
    "correct_results = []\n",
    "for i in range(train_size):\n",
    "    correct = []\n",
    "    for ci in range(10):\n",
    "        if train_label[i] == ci:\n",
    "            correct.append(1)\n",
    "        else:\n",
    "            correct.append(0)\n",
    "    correct = torch.from_numpy(np.array(correct).astype(float)).to(device)\n",
    "    correct_results.append(correct)\n",
    "\n",
    "# Train\n",
    "stats_step = 5000\n",
    "for epoch in range(20):\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    print(\"epoch: {}\".format(epoch))\n",
    "    \n",
    "    for i, data in enumerate(train_data, 0):\n",
    "        # Load input\n",
    "        input = torch.from_numpy(data.astype(float)).to(device)\n",
    "        \n",
    "        # Generate prediction\n",
    "        prediction = model(input)\n",
    "        \n",
    "        # Correct result\n",
    "        correct = correct_results[i]\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = criterion(prediction, correct)\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Perform a backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Print stats\n",
    "        running_loss += loss.item()\n",
    "        if (i % stats_step == 0) and (i > 0):\n",
    "            print(\"[{}] loss: {}\".format(i, running_loss / stats_step))\n",
    "            running_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                                                        \n",
      "                                                        \n",
      "                                                        \n",
      "                                  1 1 1 1 1 1 1         \n",
      "                1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1         \n",
      "                1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1       \n",
      "                1 1 1 1 1 1 1 1 1 1     1 1 1 1         \n",
      "                                        1 1 1 1         \n",
      "                                      1 1 1 1           \n",
      "                                      1 1 1             \n",
      "                                    1 1 1 1             \n",
      "                                    1 1 1               \n",
      "                                  1 1 1                 \n",
      "                                1 1 1 1                 \n",
      "                                1 1 1                   \n",
      "                              1 1 1 1                   \n",
      "                              1 1 1                     \n",
      "                            1 1 1 1                     \n",
      "                            1 1 1                       \n",
      "                            1 1 1                       \n",
      "                          1 1 1 1                       \n",
      "                          1 1 1                         \n",
      "                        1 1 1 1                         \n",
      "                        1 1 1                           \n",
      "                        1 1 1                           \n",
      "                      1 1 1 1                           \n",
      "                        1 1 1                           \n",
      "                                                        \n",
      "Uncertain\n",
      "0.00000000000000129346437587583629088058738852887902\n",
      "0.00000000000000000000000000000000001394796264926500\n",
      "0.00016695920357699794967475115381461137076257728040\n",
      "0.00000400471984005761850121916933797905358005664311\n",
      "0.00000000000000000000000000000000000001262079000061\n",
      "0.00000000000000000000000005774896438896024478470863\n",
      "0.00000000000000000000000000000000000000477143444974\n",
      "0.00000000000000045034435664214614974831797296616164\n",
      "0.00000000000000385600044318959682319388008615892148\n",
      "0.00000000000000000000000134764306040870916934356702\n",
      "number = 2\n"
     ]
    }
   ],
   "source": [
    "# Test model\n",
    "from PIL import Image\n",
    "\n",
    "im = Image.open('test1.png')\n",
    "pix = im.load()\n",
    "w, h = im.size\n",
    "\n",
    "pixel_list = []\n",
    "for x in range(0, w):\n",
    "    for y in range(0, h):\n",
    "        pixel_list.append(int(255 - sum(pix[y, x][0:3]) / 3))\n",
    "        \n",
    "for x in range(0, w):\n",
    "    print()\n",
    "    for y in range(0, h):\n",
    "        print(1 if pixel_list[x*28 + y] >= 128 else ' ', end=' ')\n",
    "        \n",
    "print()        \n",
    "        \n",
    "input = torch.from_numpy(np.array(pixel_list).astype(float)).to(device)\n",
    "prediction = model(input)\n",
    "\n",
    "max_v = 0\n",
    "max_n = 0\n",
    "for n, v in enumerate(prediction):\n",
    "    if v > max_v:\n",
    "        max_n = n\n",
    "        max_v = v\n",
    "\n",
    "if max_v < 0.001:\n",
    "    print(\"Uncertain\")\n",
    "        \n",
    "for i in prediction:\n",
    "    print(\"{0:.50f}\".format(i))\n",
    "\n",
    "print(\"number = {}\".format(max_n))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5000] Certain correct 98.46427776541287\n",
      "[5000] Uncertain correct 1.574803149606299\n",
      "[5000] Correct percentage 88.64\n",
      "[10000] Certain correct 98.38512083750975\n",
      "[10000] Uncertain correct 1.761252446183953\n",
      "[10000] Correct percentage 88.52\n",
      "[15000] Certain correct 98.43715280349605\n",
      "[15000] Uncertain correct 2.1999999999999997\n",
      "[15000] Correct percentage 88.82\n",
      "[20000] Certain correct 98.48291191997777\n",
      "[20000] Uncertain correct 2.1934197407776668\n",
      "[20000] Correct percentage 88.83\n",
      "[25000] Certain correct 98.4332576668002\n",
      "[25000] Uncertain correct 2.0126282557221784\n",
      "[25000] Correct percentage 88.664\n",
      "[30000] Certain correct 98.40068277116035\n",
      "[30000] Uncertain correct 2.064220183486239\n",
      "[30000] Correct percentage 88.60333333333334\n",
      "[35000] Certain correct 98.43288089259036\n",
      "[35000] Uncertain correct 2.1739130434782608\n",
      "[35000] Correct percentage 88.69428571428571\n",
      "[40000] Certain correct 98.47181628392484\n",
      "[40000] Uncertain correct 2.2080471050049066\n",
      "[40000] Correct percentage 88.665\n",
      "Final statistics\n",
      "Certain correct 98.488504680332\n",
      "Uncertain correct 2.168337607833994\n",
      "Correct percentage 88.65238095238095\n",
      "Certain 37711\n",
      "Uncertain 4289\n"
     ]
    }
   ],
   "source": [
    "# train_size = len(data)\n",
    "# train_data = data[0:train_size, 1:]\n",
    "# train_label = data[0:train_size,0]\n",
    "\n",
    "certain_correct = 0\n",
    "certain_count = 0\n",
    "\n",
    "uncertain_correct = 0\n",
    "uncertain_count = 0\n",
    "\n",
    "for i in range(train_size):\n",
    "    data = train_data[i]\n",
    "    input = torch.from_numpy(data.astype(float)).to(device)\n",
    "    \n",
    "    prediction = model(input)\n",
    "    \n",
    "    max_v = 0\n",
    "    max_n = 0\n",
    "    for n, v in enumerate(prediction):\n",
    "        if v > max_v:\n",
    "            max_n = n\n",
    "            max_v = v\n",
    "            \n",
    "    if (max_v > 0.001):\n",
    "        certain_count += 1\n",
    "        if (max_n == train_label[i]):\n",
    "            certain_correct += 1\n",
    "            \n",
    "    if (max_v < 0.001):\n",
    "        uncertain_count += 1\n",
    "        if (max_n == train_label[i]):\n",
    "            uncertain_correct += 1\n",
    "            \n",
    "    if (i % stats_step == 0) and (i > 0):\n",
    "            print(\"[{}] Certain correct {}\".format(i, certain_correct / certain_count * 100))\n",
    "            print(\"[{}] Uncertain correct {}\".format(i, uncertain_correct / uncertain_count * 100))\n",
    "            print(\"[{}] Correct percentage {}\".format(i, (certain_correct + uncertain_correct) / i * 100))\n",
    "\n",
    "print(\"Final statistics\")\n",
    "print(\"Certain correct {}\".format(certain_correct / certain_count * 100))\n",
    "print(\"Uncertain correct {}\".format(uncertain_correct / uncertain_count * 100))\n",
    "print(\"Correct percentage {}\".format((certain_correct + uncertain_correct) / train_size * 100))\n",
    "\n",
    "print(\"Certain {}\".format(certain_count))\n",
    "print(\"Uncertain {}\".format(uncertain_count))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
